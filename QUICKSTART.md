# Quick Start Guide

## 5-Minute Setup

### Step 1: Install Dependencies

```bash
pip install anthropic
```

### Step 2: Set API Key

Get your key from: https://console.anthropic.com/

```bash
export ANTHROPIC_API_KEY='sk-ant-...'
```

### Step 3: Place Required Files

Ensure these files are in the same directory:
- `transcript_processor.py`
- `parse_meeting.py` (from previous deliverable)
- Your raw meeting transcript (e.g., `meeting.md`)

### Step 4: Run!

```bash
# Estimate cost first
python transcript_processor.py meeting.md --dry-run

# Process for real
python transcript_processor.py meeting.md
```

### Step 5: Review Glossary

When prompted:
1. Open `output/TIMESTAMP_meeting/technical_terms.json`
2. Review and edit technical terms
3. Press ENTER in terminal to continue

### Step 6: Access Results

Check `output/TIMESTAMP_meeting/` for:
- âœ… `structured_en.md` - English structured version
- âœ… `structured_ru.md` - Russian structured version  
- âœ… `parsed_en.json` - English knowledge graph
- âœ… `parsed_ru.json` - Russian knowledge graph
- â„¹ï¸ `metadata.json` - Processing details & costs

## Expected Output

```
[STAGE 1] Extracting technical glossary from transcript...
  Input tokens: 20,124 | Output tokens: 4,532
âœ“ Extracted 47 technical terms across 5 categories
âœ“ Glossary saved to: output/2025-11-20_143022_meeting/technical_terms.json

USER REVIEW REQUIRED
Review and edit technical terms in: output/2025-11-20_143022_meeting/technical_terms.json
Press ENTER when ready to continue, or Ctrl+C to abort...

[STAGE 2] Translating transcript to English...
  Input tokens: 20,124 | Output tokens: 38,456
âœ“ Translation complete

[STAGE 3] Structuring English version...
  Input tokens: 38,456 | Output tokens: 40,123
âœ“ English structuring complete

[STAGE 4] Structuring Russian version...
  Input tokens: 20,124 | Output tokens: 38,890
âœ“ Russian structuring complete

[STAGE 5] Parsing and validating ENGLISH version...
âœ“ Parsed 81 nodes, 179 relationships
âœ“ All 10 validation checks passed

[STAGE 5] Parsing and validating RUSSIAN version...
âœ“ Parsed 81 nodes, 179 relationships
âœ“ All 10 validation checks passed

============================================================
PROCESSING COMPLETE
============================================================

ğŸ“ Output directory: output/2025-11-20_143022_meeting

ğŸ“„ Generated files:
  â”œâ”€ technical_terms.json       (Editable glossary)
  â”œâ”€ translated_full_en.md      (Full English translation)
  â”œâ”€ structured_en.md           (Structured English)
  â”œâ”€ structured_ru.md           (Structured Russian)
  â”œâ”€ parsed_en.json             (Knowledge graph JSON)
  â”œâ”€ parsed_ru.json             (Knowledge graph JSON)
  â””â”€ metadata.json              (Processing metadata)

ğŸ’° Cost: $2.18
  â”œâ”€ Input tokens: 98,828 ($0.30)
  â””â”€ Output tokens: 122,001 ($1.88)

â±ï¸  Time: 127.5s

ğŸ“Š Statistics:
  English: 7 topics, 6 decisions, 15 actions
  Russian: 7 topics, 6 decisions, 15 actions
```

## Common First-Time Issues

### "ModuleNotFoundError: No module named 'anthropic'"
```bash
pip install anthropic
```

### "Error: No API key provided"
```bash
export ANTHROPIC_API_KEY='your-key-here'
```

### "parse_meeting.py not found"
Copy `parse_meeting.py` to the same directory as `transcript_processor.py`

## Pro Tips

ğŸ’¡ **Always dry-run first**: See estimated cost before processing
```bash
python transcript_processor.py meeting.md --dry-run
```

ğŸ’¡ **Skip review for batch processing**: Use `--skip-review` flag
```bash
python transcript_processor.py meeting.md --skip-review
```

ğŸ’¡ **Keep glossaries**: Save edited glossaries for similar meetings
```bash
cp output/*/technical_terms.json templates/glossary_team_sync.json
```

## What's Next?

1. âœ… Review structured markdown files
2. âœ… Import JSON to Neo4j (see main README)
3. âœ… Query your knowledge graph
4. ğŸ”„ Process more transcripts (batch script in README)

## Need Help?

Check the main README for:
- Detailed usage examples
- Troubleshooting guide
- Validation explanations
- Neo4j integration
- Batch processing scripts

## Example Input Format

Your transcript should look like this (Russian + English terms):

```markdown
# Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸

**Ğ”Ğ°Ñ‚Ğ°:** 2025-11-19
**Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 00:25:28
**Ğ£Ñ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¸:** Person1, Person2, Person3

---

**Person1** [00:00:00 - 00:00:23]: ĞŸĞ¾ DestinationDriver ĞµÑÑ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾Ğµ?

**Person2** [00:00:23 - 00:00:40]: Ğ¯ ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑÑŒ ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ°Ğ¼Ğ¸ Ğ² Destinations...
```

The script handles:
- Mixed Russian/English
- Technical terminology
- Timestamps
- Speaker attribution
- Informal conversation style

That's it! Start processing your first transcript now! ğŸš€
